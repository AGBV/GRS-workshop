{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1244e1c",
   "metadata": {},
   "source": [
    "# Application of Machine Learning Algorithms to GRS Data in Python\n",
    "\n",
    "**By Tom Sander**\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to apply **unsupervised machine learning** (specifically K-Means clustering) to **Lunar Prospector Gamma-Ray Spectrometer (GRS)** data. By the end of this tutorial, you will:\n",
    "\n",
    "1. Load and preprocess NASA planetary data\n",
    "2. Understand why data normalization is critical for ML\n",
    "3. Use the **Elbow Method** to determine the optimal number of clusters\n",
    "4. Create an automated **geochemical map** of the Moon\n",
    "5. Interpret the results in terms of known lunar geology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a01be0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Import Packages\n",
    "\n",
    "We'll use the following libraries:\n",
    "- **Polars**: A fast DataFrame library for data manipulation (similar to Pandas but faster) [polars-website](https://pola.rs/)\n",
    "- **Matplotlib**: For creating visualizations [matplotlib-website](https://matplotlib.org/)\n",
    "- **Scikit-learn**: For machine learning algorithms (imported later) [scikit-learn-website](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation library - Polars is a high-performance alternative to Pandas\n",
    "import polars as pl\n",
    "\n",
    "# Visualization library for creating plots and maps\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bbdcc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load Data\n",
    "\n",
    "The Lunar Prospector GRS data is stored in NASA's PDS (Planetary Data System) format. The `.tab` file contains the actual data in a fixed-width, whitespace-separated format with 61 columns per record.\n",
    "\n",
    "**Data Source:** [NASA PDS Geosciences Node](https://pds-geosciences.wustl.edu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e3574",
   "metadata": {},
   "source": [
    "### Custom Data Loader Function\n",
    "\n",
    "NASA PDS files have a specific format that requires custom parsing. The function below:\n",
    "1. Reads all whitespace-separated tokens from the file\n",
    "2. Reshapes them into records of 61 columns each\n",
    "3. Converts scientific notation strings to float values\n",
    "4. Renames columns to human-readable element names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4db277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lpgrs_tab(filepath: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a Lunar Prospector GRS .tab file into a Polars DataFrame.\n",
    "    \n",
    "    Handles wrapped lines, multiple-space delimiters, and scientific notation.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the .tab file.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame containing the GRS data with appropriate column names.\n",
    "    \"\"\"\n",
    "    # Step 1: Read all whitespace-separated tokens\n",
    "    # NASA records are often wrapped across multiple lines\n",
    "    with open(filepath, 'r') as f:\n",
    "        tokens = f.read().split()\n",
    "    \n",
    "    # Step 2: Reshape into 61 columns (standard format for GRS abundance files)\n",
    "    # The 5-degree resolution file contains approximately 1,300 records\n",
    "    record_width = 61\n",
    "    rows = [tokens[i : i + record_width] for i in range(0, len(tokens), record_width)]\n",
    "    \n",
    "    # Step 3: Create DataFrame and cast scientific notation strings to Float64\n",
    "    df = pl.DataFrame(rows, orient=\"row\").select([\n",
    "        pl.all().cast(pl.Float64)\n",
    "    ])\n",
    "    \n",
    "    # Step 4: Define human-readable column names for the first 16 columns\n",
    "    # These represent the key geochemical measurements from the GRS instrument\n",
    "    names = [\n",
    "        \"bin_index\",    # Unique identifier for each spatial bin\n",
    "        \"lat_start\",    # Starting latitude of the bin (degrees)\n",
    "        \"lat_end\",      # Ending latitude of the bin (degrees)\n",
    "        \"lon_start\",    # Starting longitude of the bin (degrees)\n",
    "        \"lon_end\",      # Ending longitude of the bin (degrees)\n",
    "        \"thorium\",      # Thorium abundance (ppm) - key KREEP indicator\n",
    "        \"th_err\",       # Thorium measurement uncertainty\n",
    "        \"potassium\",    # Potassium abundance (wt%) - key KREEP indicator\n",
    "        \"k_err\",        # Potassium measurement uncertainty\n",
    "        \"iron\",         # Iron abundance (wt%) - high in mare basalts\n",
    "        \"fe_err\",       # Iron measurement uncertainty\n",
    "        \"titanium\",     # Titanium abundance (wt%) - high in high-Ti mare basalts\n",
    "        \"ti_err\",       # Titanium measurement uncertainty\n",
    "        \"samarium\",     # Samarium abundance (ppm) - rare earth element\n",
    "        \"sm_err\",       # Samarium measurement uncertainty\n",
    "        \"calcium\"       # Calcium abundance (wt%) - high in anorthosites\n",
    "    ]\n",
    "    \n",
    "    # Select only the 16 columns we need and apply the new names\n",
    "    return df.select(df.columns[:16]).rename(\n",
    "        {old: new for old, new in zip(df.columns[:16], names)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to data files\n",
    "# The dataset includes three file types:\n",
    "#   .tab - The actual data (tabular format)\n",
    "#   .lbl - Label file describing the data structure\n",
    "#   .xml - Metadata in XML format\n",
    "path_to_tab = \"data/lpgrs_high1_elem_abundance_5deg.tab\"\n",
    "path_to_lbl = \"data/lpgrs_high1_elem_abundance_5deg.lbl\"\n",
    "path_to_xml = \"data/lpgrs_high1_elem_abundance_5deg.xml\"\n",
    "\n",
    "# Load the GRS data into a Polars DataFrame\n",
    "df = load_lpgrs_tab(path_to_tab)\n",
    "\n",
    "# Display the first few rows to verify the data loaded correctly\n",
    "print(f\"Loaded {df.height} records with {df.width} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1756e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Preparation & Normalization\n",
    "\n",
    "Before applying machine learning algorithms, we need to prepare our data properly. This involves two critical steps:\n",
    "1. **Data Cleaning**: Removing invalid or missing values\n",
    "2. **Feature Scaling**: Normalizing the data to a common scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2af091",
   "metadata": {},
   "source": [
    "### 3.1 Feature Selection & Data Cleaning\n",
    "\n",
    "Machine learning models are sensitive to **\"dirty\" data**. Before we begin, we must ensure our dataset is clean.\n",
    "\n",
    "We will filter our dataset to keep only the columns relevant to geochemistry:\n",
    "- **Iron (Fe)** - Indicates mafic (basaltic) content\n",
    "- **Titanium (Ti)** - Distinguishes high-Ti from low-Ti mare basalts\n",
    "- **Thorium (Th)** - Key tracer for KREEP material\n",
    "- **Potassium (K)** - Another KREEP indicator\n",
    "\n",
    "> âš ï¸ **Important:** We specifically exclude Latitude and Longitude from the training data because we want the model to group pixels based on **composition**, not their physical location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4044bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the geochemical features we want to analyze\n",
    "# These elements are diagnostic of different lunar rock types\n",
    "feature_cols = ['iron', 'titanium', 'thorium', 'potassium']\n",
    "\n",
    "# Drop rows where any of these values are null to prevent errors during ML training\n",
    "# This ensures we only work with complete records\n",
    "df_clean = df.drop_nulls(subset=feature_cols)\n",
    "\n",
    "# Report how many rows were removed (if any)\n",
    "print(f\"Original dataset size: {df.height} rows\")\n",
    "print(f\"Clean dataset size: {df_clean.height} rows\")\n",
    "print(f\"Rows removed: {df.height - df_clean.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0408f96",
   "metadata": {},
   "source": [
    "### 3.2 Standardization (The \"Apples to Oranges\" Problem)\n",
    "\n",
    "Geochemical data often comes in **mixed units**:\n",
    "- **Iron (Fe)**: Measured in weight percent (`0-20 wt%`)\n",
    "- **Thorium (Th)**: Measured in parts per million (`0-15 ppm`)\n",
    "\n",
    "If we do not normalize this data, the K-Means algorithm will be **biased**. It will think Iron is \"more important\" simply because the numbers are larger.\n",
    "\n",
    "We use `StandardScaler` to transform each feature to have:\n",
    "- **Mean = 0**\n",
    "- **Standard Deviation = 1**\n",
    "Each row will be subtracted its mean $\\mu$ and being divided by its Standard Deviation $\\sigma$:\n",
    "\n",
    "$ x = \\frac{x - \\mu}{\\sigma}$\n",
    "\n",
    "This forces all elements onto a level playing field, ensuring equal contribution to the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the StandardScaler from scikit-learn's preprocessing module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert the Polars DataFrame columns to a NumPy array\n",
    "# Scikit-learn requires NumPy arrays as input\n",
    "X_raw = df_clean.select(feature_cols).to_numpy()\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "# This will compute mean and std for each feature\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to our data and transform it in one step\n",
    "# fit_transform() learns the parameters AND applies the transformation\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "# Verify the transformation worked correctly\n",
    "print(\"Data standardization complete.\")\n",
    "print(f\"\\nExample comparison for first data point:\")\n",
    "print(f\"  Raw Fe value:    {X_raw[0][0]:.4f} wt%\")\n",
    "print(f\"  Scaled Fe value: {X_scaled[0][0]:.4f} (standardized)\")\n",
    "print(f\"\\nScaling parameters learned:\")\n",
    "print(f\"  Feature means: {scaler.mean_}\")\n",
    "print(f\"  Feature stds:  {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f351c04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. The Elbow Method: Finding the Optimal Number of Clusters\n",
    "\n",
    "How many distinct geochemical terranes exist on the Moon? Instead of guessing, we use the **\"Elbow Method\"**.\n",
    "\n",
    "### How it works:\n",
    "1. Run K-Means multiple times with different values of **k** (number of clusters)\n",
    "2. Calculate the **Inertia** for each run (sum of squared distances from each point to its cluster center)\n",
    "3. Plot inertia vs. k and look for the **\"elbow\"** â€” the point where adding more clusters provides diminishing returns\n",
    "\n",
    "> ðŸ’¡ **Tip:** The elbow represents the optimal trade-off between model complexity and clustering quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the K-Means clustering algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# List to store inertia values for each k\n",
    "inertia = []\n",
    "\n",
    "# Test k values from 1 to 9 clusters\n",
    "k_range = range(1, 10)\n",
    "\n",
    "print(\"Running Elbow Method test...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Iterate through each value of k\n",
    "for k in k_range:\n",
    "    # Initialize KMeans with current k value\n",
    "    # random_state=42 ensures reproducibility\n",
    "    # n_init=10 means it runs 10 times with different random seeds and picks the best\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    \n",
    "    # Fit the model to our scaled data\n",
    "    kmeans_temp.fit(X_scaled)\n",
    "    \n",
    "    # Store the inertia (within-cluster sum of squares)\n",
    "    inertia.append(kmeans_temp.inertia_)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"  k={k}: Inertia = {kmeans_temp.inertia_:.2f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Elbow Method complete!\")\n",
    "\n",
    "# Create the Elbow plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia, marker='o', linestyle='-', color='b', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
    "plt.ylabel('Inertia (Sum of Squared Distances)', fontsize=12)\n",
    "plt.title('The Elbow Method: Determining Optimal Number of Clusters', fontsize=14)\n",
    "plt.xticks(k_range)  # Show all k values on x-axis\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotation pointing to the likely elbow\n",
    "plt.annotate('Elbow point', xy=(3, inertia[2]), xytext=(4.5, inertia[2] + 500),\n",
    "             arrowprops=dict(arrowstyle='->', color='red'), fontsize=11, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422b66e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Running the Classification Model\n",
    "\n",
    "Based on the Elbow plot above, we see a clear bend around **k=3**. This aligns with the three major lunar terranes known from geological studies:\n",
    "\n",
    "| Cluster | Terrane | Characteristics |\n",
    "|---------|---------|-----------------|\n",
    "| 1 | **Procellarum KREEP Terrane (PKT)** | High Th, High K, elevated Fe |\n",
    "| 2 | **Feldspathic Highlands Terrane (FHT)** | Low Th, Low Fe, high Ca |\n",
    "| 3 | **South Pole-Aitken Basin (SPA)** | Intermediate Fe, anomalous Th |\n",
    "\n",
    "Now we run the final model with **k=3** and assign each pixel a \"Geochemical Cluster ID.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the optimal number of clusters based on the Elbow plot analysis\n",
    "k_optimal = 3 \n",
    "\n",
    "# Initialize the final K-Means model\n",
    "# random_state ensures reproducible results across runs\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)\n",
    "\n",
    "# Fit the model and predict cluster labels in one step\n",
    "# fit_predict() is equivalent to fit() followed by predict()\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Attach the resulting Cluster IDs back to our clean DataFrame\n",
    "# This allows us to visualize results geographically\n",
    "df_results = df_clean.with_columns(\n",
    "    pl.Series(name=\"Cluster_ID\", values=labels)\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"=\" * 50)\n",
    "print(\"CLUSTERING COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of clusters: {k_optimal}\")\n",
    "print(f\"Total pixels classified: {len(labels)}\")\n",
    "print(f\"\\nPixels per cluster:\")\n",
    "for i in range(k_optimal):\n",
    "    count = (labels == i).sum()\n",
    "    percentage = count / len(labels) * 100\n",
    "    print(f\"  Cluster {i}: {count} pixels ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c6806a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Visualization: The Machine Learning Geologic Map\n",
    "\n",
    "Now we can visualize our results by plotting each pixel at its geographic location, colored by its assigned cluster.\n",
    "\n",
    "**Key Questions to Consider:**\n",
    "- Does the algorithm successfully identify the dark **Mare** regions (iron-rich basaltic plains)?\n",
    "- Does it separate the bright **Highlands** (feldspathic, low-iron terrain)?\n",
    "- Can you spot the **South Pole-Aitken Basin** (large impact basin on the far side)?\n",
    "\n",
    "> ðŸ”¬ **Note:** The algorithm found these distinct regions based purely on chemistry, without ever knowing the latitude or longitude of the data points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with appropriate size for lunar map\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create the scatter plot using geographic coordinates\n",
    "# Each point represents a 5-degree bin on the lunar surface\n",
    "# Calculate the center and size of each bin for rectangle patches\n",
    "\n",
    "# Create rectangle patches for each bin\n",
    "patches = []\n",
    "colors = []\n",
    "for i in range(len(df_results)):\n",
    "    row = df_results.row(i, named=True)\n",
    "    width = row['lon_end'] - row['lon_start']\n",
    "    height = row['lat_end'] - row['lat_start']\n",
    "    rect = Rectangle((row['lon_start'], row['lat_start']), width, height)\n",
    "    patches.append(rect)\n",
    "    colors.append(row['Cluster_ID'])\n",
    "\n",
    "# Create a PatchCollection with the rectangles\n",
    "collection = PatchCollection(patches, cmap='viridis', alpha=0.8)\n",
    "collection.set_array(colors)\n",
    "collection.set_clim(0, 2)\n",
    "\n",
    "# Add the collection to the axes\n",
    "ax = plt.gca()\n",
    "ax.add_collection(collection)\n",
    "scatter = collection  # For colorbar compatibility\n",
    "\n",
    "# Add colorbar to show cluster ID mapping\n",
    "cbar = plt.colorbar(scatter, label='Geochemical Cluster ID')\n",
    "cbar.set_ticks([0, 1, 2])\n",
    "cbar.set_ticklabels(['Cluster 0', 'Cluster 1', 'Cluster 2'])\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Longitude (degrees)', fontsize=12)\n",
    "plt.ylabel('Latitude (degrees)', fontsize=12)\n",
    "plt.title(f'Unsupervised Geochemical Map of the Moon (k={k_optimal})', fontsize=14)\n",
    "\n",
    "# Add grid for easier geographic reference\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "\n",
    "# Set axis limits to full lunar coverage\n",
    "plt.xlim(-180, 180)\n",
    "plt.ylim(-90, 90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d9fa3",
   "metadata": {},
   "source": [
    "## 6.1 Scatter plot of two features plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(8)\n",
    "ax.scatter(df_results[\"iron\"], df_results[\"thorium\"], s=16, c=df_results[\"Cluster_ID\"], cmap='Paired', alpha=0.7) # c=\"white\"\n",
    "ax.set_xlabel('Iron (wt%)', fontsize=14)\n",
    "ax.set_ylabel('Thorium (ppm)', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "# Set the background color to a custom RGB value...\n",
    "ax.set_facecolor('xkcd:salmon')\n",
    "ax.set_facecolor((0.13, 0.13, 0.13))\n",
    "fig.set_facecolor((0.13, 0.13, 0.13))\n",
    "# Set the borders to a given color...\n",
    "ax.xaxis.label.set_color('white')\n",
    "ax.yaxis.label.set_color('white')\n",
    "ax.tick_params(color='white', labelcolor='white')\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor('white')\n",
    "    spine.set_color('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63940ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Geological Interpretation: Decoding the Clusters\n",
    "\n",
    "A map is useful, but we need to understand the **chemistry behind the colors**. By grouping the data by Cluster ID and calculating the mean of each element, we can create a \"chemical fingerprint\" for each terrane.\n",
    "\n",
    "### Interpretation Guide:\n",
    "\n",
    "| Chemistry Signature | Likely Terrane |\n",
    "|---------------------|----------------|\n",
    "| **High Th, High K, High Fe** | Procellarum KREEP Terrane (PKT) or Mare basalts |\n",
    "| **Low Th, Low Fe, Low Ti** | Feldspathic Highlands Terrane (FHT) |\n",
    "| **Intermediate Fe, Variable Th** | South Pole-Aitken Basin (SPA) |\n",
    "\n",
    "> ðŸ“– **KREEP** = Potassium (K), Rare Earth Elements (REE), Phosphorus (P) â€” a geochemical signature of the last dregs of the lunar magma ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d39cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean chemistry for each cluster\n",
    "# This creates a \"fingerprint\" for each geochemical terrane\n",
    "cluster_stats = df_results.group_by(\"Cluster_ID\").agg([\n",
    "    pl.col(\"iron\").mean().alias(\"Avg_Fe_wt%\"),       # Average iron content\n",
    "    pl.col(\"titanium\").mean().alias(\"Avg_Ti_wt%\"),   # Average titanium content\n",
    "    pl.col(\"thorium\").mean().alias(\"Avg_Th_ppm\"),    # Average thorium content\n",
    "    pl.col(\"potassium\").mean().alias(\"Avg_K_wt%\"),   # Average potassium content\n",
    "    pl.len().alias(\"Pixel_Count\")                     # Number of pixels in cluster\n",
    "]).sort(\"Cluster_ID\")\n",
    "\n",
    "# Display the cluster statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"CLUSTER GEOCHEMICAL SIGNATURES\")\n",
    "print(\"=\" * 60)\n",
    "print(cluster_stats)\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nCompare these values to known lunar terrane compositions to identify which cluster corresponds to which region!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0953cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusions & Next Steps\n",
    "\n",
    "### What We Accomplished:\n",
    "- Successfully loaded and processed NASA Lunar Prospector GRS data  \n",
    "- Applied K-Means clustering to identify geochemically distinct regions  \n",
    "- Created an automated geochemical map of the Moon  \n",
    "- Identified three major terranes matching known lunar geology  \n",
    "\n",
    "### Ideas for Further Exploration:\n",
    "- Try different values of **k** (4, 5, 6) to see if sub-terranes emerge\n",
    "- Experiment with other clustering algorithms (DBSCAN, Hierarchical Clustering)\n",
    "- Add more elements to the feature set (Samarium, Calcium)\n",
    "- Compare your results to published lunar terrane maps\n",
    "- Apply the same technique to Mars GRS data!\n",
    "\n",
    "---\n",
    "\n",
    "*KMeans Workshop file complete! Continue with DBSCAN*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
